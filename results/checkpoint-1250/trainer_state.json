{
  "best_global_step": 1250,
  "best_metric": 0.6926709365400955,
  "best_model_checkpoint": "./results\\checkpoint-1250",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 1250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 2.0624990463256836,
      "learning_rate": 1.9216e-05,
      "loss": 0.6954,
      "step": 50
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.154463529586792,
      "learning_rate": 1.8416e-05,
      "loss": 0.6808,
      "step": 100
    },
    {
      "epoch": 0.24,
      "grad_norm": 5.5683088302612305,
      "learning_rate": 1.7616000000000002e-05,
      "loss": 0.6823,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 5.656729221343994,
      "learning_rate": 1.6816e-05,
      "loss": 0.6636,
      "step": 200
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.612738847732544,
      "learning_rate": 1.6016e-05,
      "loss": 0.6699,
      "step": 250
    },
    {
      "epoch": 0.48,
      "grad_norm": 9.02340316772461,
      "learning_rate": 1.5216000000000001e-05,
      "loss": 0.6547,
      "step": 300
    },
    {
      "epoch": 0.56,
      "grad_norm": 6.986550807952881,
      "learning_rate": 1.4416e-05,
      "loss": 0.6549,
      "step": 350
    },
    {
      "epoch": 0.64,
      "grad_norm": 6.552659034729004,
      "learning_rate": 1.3616e-05,
      "loss": 0.651,
      "step": 400
    },
    {
      "epoch": 0.72,
      "grad_norm": 6.6246209144592285,
      "learning_rate": 1.2816000000000002e-05,
      "loss": 0.6429,
      "step": 450
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.867398738861084,
      "learning_rate": 1.2016000000000002e-05,
      "loss": 0.6485,
      "step": 500
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.154941082000732,
      "learning_rate": 1.1216e-05,
      "loss": 0.6392,
      "step": 550
    },
    {
      "epoch": 0.96,
      "grad_norm": 10.513190269470215,
      "learning_rate": 1.0416000000000002e-05,
      "loss": 0.6157,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.675,
      "eval_f1": 0.6746478972049257,
      "eval_loss": 0.6175822019577026,
      "eval_runtime": 7.4707,
      "eval_samples_per_second": 133.856,
      "eval_steps_per_second": 16.732,
      "step": 625
    },
    {
      "epoch": 1.04,
      "grad_norm": 6.330918312072754,
      "learning_rate": 9.616e-06,
      "loss": 0.5993,
      "step": 650
    },
    {
      "epoch": 1.12,
      "grad_norm": 19.046775817871094,
      "learning_rate": 8.816000000000002e-06,
      "loss": 0.6123,
      "step": 700
    },
    {
      "epoch": 1.2,
      "grad_norm": 12.547391891479492,
      "learning_rate": 8.016e-06,
      "loss": 0.6074,
      "step": 750
    },
    {
      "epoch": 1.28,
      "grad_norm": 5.822692394256592,
      "learning_rate": 7.216000000000001e-06,
      "loss": 0.6067,
      "step": 800
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 11.117453575134277,
      "learning_rate": 6.416e-06,
      "loss": 0.5931,
      "step": 850
    },
    {
      "epoch": 1.44,
      "grad_norm": 4.678772926330566,
      "learning_rate": 5.616e-06,
      "loss": 0.5924,
      "step": 900
    },
    {
      "epoch": 1.52,
      "grad_norm": 4.58753776550293,
      "learning_rate": 4.816e-06,
      "loss": 0.6039,
      "step": 950
    },
    {
      "epoch": 1.6,
      "grad_norm": 10.70373249053955,
      "learning_rate": 4.016e-06,
      "loss": 0.6022,
      "step": 1000
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 4.3794660568237305,
      "learning_rate": 3.216e-06,
      "loss": 0.5712,
      "step": 1050
    },
    {
      "epoch": 1.76,
      "grad_norm": 11.661422729492188,
      "learning_rate": 2.4160000000000002e-06,
      "loss": 0.5896,
      "step": 1100
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 3.451312303543091,
      "learning_rate": 1.616e-06,
      "loss": 0.5687,
      "step": 1150
    },
    {
      "epoch": 1.92,
      "grad_norm": 9.426088333129883,
      "learning_rate": 8.160000000000001e-07,
      "loss": 0.5623,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "grad_norm": 8.05104923248291,
      "learning_rate": 1.6e-08,
      "loss": 0.6012,
      "step": 1250
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.698,
      "eval_f1": 0.6926709365400955,
      "eval_loss": 0.5921501517295837,
      "eval_runtime": 6.9389,
      "eval_samples_per_second": 144.115,
      "eval_steps_per_second": 18.014,
      "step": 1250
    }
  ],
  "logging_steps": 50,
  "max_steps": 1250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6352435200000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
